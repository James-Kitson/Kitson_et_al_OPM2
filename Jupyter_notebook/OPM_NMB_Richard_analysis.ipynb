{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Jupyter notebook for processing analysis run 2 as presented in Kitson _et al._ 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Downloading raw read data from SRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell will download the raw Illumina data associated with the study and rename the files as specified in the text file `SraAccList.txt` provided in the `data` directory.\n",
    "\n",
    "The cell expects modules of the [SRA Toolkit](http://www.ncbi.nlm.nih.gov/Traces/sra/?view=toolkit_doc) (`prefetch` and `fastq-dump`) to be in your path (tested with SRA Toolkit version 2.3.5). `prefetch` downloads data in sra format and places it per default into `~/ncbi/public/sra/`. `fastq-dump` converts the sra formatted data to gzipped fastq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sra_path=\"~/ncbi/public/sra\"\n",
    "\n",
    "cd data\n",
    "\n",
    "for line in $(cat SraAccList_run2.txt)\n",
    "do \n",
    "    name=$(echo -e \"$line\" | cut -d \",\" -f 1)\n",
    "    acc=$(echo -e \"$line\" | cut -d \",\" -f 2)\n",
    "    \n",
    "    prefetch $acc\n",
    "    fastq-dump --split-files --gzip --defline-seq '@$ac-$sn/$ri' --defline-qual '+' $sra_path/$acc.sra\n",
    "    mv $acc\\_1.fastq.gz $name\\_1.fastq.gz\n",
    "    mv $acc\\_2.fastq.gz $name\\_2.fastq.gz\n",
    "done\n",
    "\n",
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Processing read data\n",
    "To ensure complete reproducibility all subsequent processing of the read data was performed in a docker container which we have made available [here](https://hub.docker.com/r/chrishah/metabeat/).\n",
    "\n",
    "The following cell will print out the help file for metaBEAT_global.py allowing readers to follow the commands used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "metaBEAT_global.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###PERFORM A CLUSTERING ANALYSIS TO CHECK FOR OPTIMAL CLUSTER READ DEPTH\n",
    "We will ultimately be clustering and filtering our data to unique sequences but we don't know what read depth we should accept as a minimum valid cluster size. To investigate this we will iterate across different minimum read depths and examine the effect this has on clusters retained for taxonomic assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Move to the correct folder\n",
    "mkdir -p ../Processed_data/Cluster_size\n",
    "cd ../Processed_data/Cluster_size\n",
    "\n",
    "# Loop across minimum cluster sizes\n",
    "for i in $(seq 71 5 101)\n",
    "do\n",
    "      echo -e \"running with coverage $i\"\n",
    "      metaBEAT_global.py -Q ../../data/QueryMap_all.txt --cluster --merge --merged_only \\\n",
    "      --length_filter 310 --product_length 400 --clust_match 1.0 --clust_cov $i \\\n",
    "      --trim_minlength 100 -@ James.Kitson@newcastle.ac.uk -o metaBEAT &> cluster_log$i.txt\n",
    "      mv metaBEAT_read_stats.csv metaBEAT_read_stats_$i.csv\n",
    "done\n",
    "\n",
    "# Combine the files into one large output for plotting in R\n",
    "cat metaBEAT_read_stats_6.csv | head -n 1 > ../../data/Richard_combined_read_stats_all.csv\n",
    "cat metaBEAT_read_stats_* | grep \"sample,\" -v >> ../../data/Richard_combined_read_stats_all.csv\n",
    "cd ..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###PERFORM A MISTAGGING ANALYSIS TO CHECK FOR BACKGROUND NOISE READ DEPTH\n",
    "We also need to check the illegal tag combinations to make sure that mistagging is minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Move to the correct folder\n",
    "mkdir -p ../Processed_data/Cluster_size/run2_mistag\n",
    "cd ../Processed_data/Cluster_size/run2_mistag\n",
    "\n",
    "# Loop across minimum cluster sizes\n",
    "for i in $(seq 6 5 101)\n",
    "do\n",
    "      echo -e \"running with coverage $i\"\n",
    "      metaBEAT_global.py -Q ../../../data/Illegal_QueryMap_run2.txt --cluster --merge --merged_only \\\n",
    "      --length_filter 310 --product_length 400 --clust_match 1.0 --clust_cov $i \\\n",
    "      --trim_minlength 100 -@ James.Kitson@newcastle.ac.uk -o metaBEAT &> cluster_log_$i.txt\n",
    "      mv metaBEAT_read_stats.csv metaBEAT_read_stats_$i.csv\n",
    "done\n",
    "\n",
    "# Combine the files into one large output for plotting in R\n",
    "cat metaBEAT_read_stats_6.csv | head -n 1 > ../../../data/combined_illegal_read_stats_run2.csv\n",
    "cat metaBEAT_read_stats_* | grep \"sample,\" -v >> ../../../data/combined_illegal_read_stats_run2.csv\n",
    "cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###PERFORMING FINAL ANALYSES (INCL. TAXONOMIC ASSIGNMENT) FROM RAW READ DATA\n",
    "####From the clustering analysis we have two possible thresholds for minimum cluster size that we could use:\n",
    "\n",
    "* Minimum cluster size for clean negatives - __> ~36 reads__.\n",
    "* Minimum cluster size for stable read depths across wells (i.e. removal of rare sequences) - __> ~51 reads__.\n",
    "\n",
    "####From the mistagging analysis we have an additional minimum cluster size we can use:\n",
    "\n",
    "* Minimum cluster size for mistagging removal - __> ~66 reads__.\n",
    "\n",
    "####We will now iterate across these values and compare sequencing success in the [Rnotebook](https://github.com/HullUni-bioinformatics/Kitson_et_al_NMB/blob/master/R_plotting_notebook_run2.Rmd) to examine what effect this has on the ecological parameters we are interested in:\n",
    " \n",
    "1. Parasitoid identity.\n",
    "2. Percentage parasitism for each Parasitoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Move to the correct folder\n",
    "mkdir -p ../Processed_data/Final_analysis\n",
    "cd ../Processed_data/Final_analysis\n",
    "\n",
    "metaBEAT_global.py -Q ../../data/QueryMap_all.txt --cluster --merge --merged_only \\\n",
    "      --length_filter 310 --product_length 400 --clust_match 1.0 --clust_cov 50 --trim_minlength 100 -E \\\n",
    "      -n 6 -v --blast --blast_db ../../../../Genbank/nt/nt \\\n",
    "      --min_ident 0.95 --min_ali_length 0.90 -@ James.Kitson@newcastle.ac.uk &> OPM_Richard_BLAST_log.txt\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MetaBEAT produces files in the .biom format for easy use with QIIME but we will be using the output in R for plotting figures. The next cell strips out all the QIIME .biom formatting and leaves us with a rectangular read table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ../Processed_data/Final_analysis/\n",
    "\n",
    "cat ./GLOBAL/BLAST_0.95/metaBEAT-by-taxonomy-readcounts.blast.tsv | \\\n",
    "grep \"# \" -v | sed 's/#//' | sed 's/\\.blast//g' | sed 's/ /_/' | perl -ne \\\n",
    "'chomp; @a=split(\"\\t\"); pop(@a); $out=join(\"\\t\", @a); print \"$out\\n\"' \\\n",
    "> ./GLOBAL/BLAST_0.95/metaBEAT-processed.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reformatted metaBEAT data could be used as is but we'll transpose our table now to make life easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "filename = \"../Processed_data/Final_analysis/GLOBAL/BLAST_0.95/metaBEAT-processed.tsv\"\n",
    "output_filename = \"../data/Richard_metaBEAT_transpose.tsv\"\n",
    "\n",
    "df = pd.read_table(filename)\n",
    "df = df.transpose()\n",
    "df.to_csv(output_filename, header=None, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
